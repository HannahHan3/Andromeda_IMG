{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32b9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_img(imgpath):\n",
    "    \"\"\"Load image.\n",
    "    \n",
    "    Args:\n",
    "        imgpath (string): The path of the image to load.\n",
    "    Returns:\n",
    "        ((int, int), torch.Tensor): The size of original image, and the normalized image tensor. \n",
    "    \"\"\"\n",
    "    img = Image.open(imgpath)\n",
    "    ori_size = img.size\n",
    "    \n",
    "    transforms = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_tensor = transforms(img)\n",
    "\n",
    "    return (ori_size, img_tensor)\n",
    "\n",
    "def save_img(grad):\n",
    "    \"\"\"Save result image.\n",
    "    This function convert the gradient result into image, then write to file.\n",
    "    Args:\n",
    "        grad (torch.Tensor): The image tensor used by the model, shape (3, 224, 224).\n",
    "        path (string): The output file path.\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "    img = grad.detach().cpu().permute(1, 2, 0).numpy()\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    img = np.uint8(255*img)\n",
    "    img_list.append(img)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "#     cv2.imwrite(f\"{path}\", img)\n",
    "#     print(f\"Save {path} complete\")\n",
    "\n",
    "    return img_list\n",
    "\n",
    "\n",
    "class GBP(nn.Module):\n",
    "    \"\"\"\n",
    "    guided backprop\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GBP, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.set_backprop()\n",
    "\n",
    "    def set_backprop(self):\n",
    "        \"\"\"Setting up backpropagation of Guided Backpropagation\n",
    "        \"\"\"\n",
    "        # Hook function. Filter out all the negative gradients and pass through.\n",
    "        def relu_backward_hook(module, grad_out, grad_in):\n",
    "            modified_grad_out = nn.functional.relu(grad_out[0])\n",
    "            return (modified_grad_out, )\n",
    "\n",
    "        # Register the backward hook function for all ReLU layers.\n",
    "        for idx, item in enumerate(self.model.modules()):\n",
    "            if isinstance(item, nn.ReLU):\n",
    "                item.register_backward_hook(relu_backward_hook)\n",
    "\n",
    "\n",
    "    def generate_gradient(self, input, target):\n",
    "        # Forward through network\n",
    "        input.requires_grad = True\n",
    "        model_output = self.model(input)\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # Build initial gradient\n",
    "        init_grad = torch.zeros_like(model_output).float()\n",
    "        init_grad[0][target] = 1.\n",
    "\n",
    "        # Backward through network\n",
    "        model_output.backward(gradient=init_grad)\n",
    "\n",
    "        # Return the gradient\n",
    "        return input.grad\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return self.generate_gradient(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2aab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = \"demo\"\n",
    "class_idx = 243 # Mastiff\n",
    "\n",
    "img_path = os.path.join(\"./\", img_id+'.jpeg')\n",
    "\n",
    "_, img_tensor = load_img(img_path)\n",
    "\n",
    "model = GBP()\n",
    "# img_tensor.unsqueeze_(0)\n",
    "# grad = model(img_tensor, class_idx)\n",
    "\n",
    "# img_list = save_img(grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b8c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG = 'SEEDS';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4db8046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6468deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "# src = cv.resize(img_tensor, 0.5, 0.5, 'Interpolation','Area');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ad3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv.imread(\"./demo.jpeg\");\n",
    "converted = cv.cvtColor(src, cv.COLOR_RGB2Lab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e23766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "cropAI",
   "language": "python",
   "name": "cropai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
